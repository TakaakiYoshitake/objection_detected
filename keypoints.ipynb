{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.058768510818481445s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 1 usage\n",
      "Finished in 14.0465407371521s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "options = {\"model\": \"cfg/yolo.cfg\", \"load\": \"bin/yolo.weights\", \"threshold\": 0.1, \"gpu\": 1}\n",
    "\n",
    "tfnet = TFNet(options)\n",
    "\n",
    "class_names = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "              'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
    "              'dog', 'horse', 'motorbike', 'person', 'pottedplant',\n",
    "              'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "files = glob.glob(\"./sample_img/*\")\n",
    "for f in files:\n",
    "    imgcv = cv2.imread(f)\n",
    "# imgcv = cv2.imread(\"./sample_img/386_720.jpeg\")\n",
    "    result = tfnet.return_predict(imgcv)\n",
    "#     print(result)\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "    class_colors = []\n",
    "    for i in range(0, num_classes):\n",
    "        hue = 255*i/num_classes\n",
    "        col = np.zeros((1,1,3)).astype(\"uint8\")\n",
    "        col[0][0][0] = hue\n",
    "        col[0][0][1] = 128\n",
    "        col[0][0][2] = 255\n",
    "        cvcol = cv2.cvtColor(col, cv2.COLOR_HSV2BGR)\n",
    "        col = (int(cvcol[0][0][0]), int(cvcol[0][0][1]), int(cvcol[0][0][2]))\n",
    "        class_colors.append(col)\n",
    "\n",
    "    for item in result:\n",
    "        tlx = item['topleft']['x']\n",
    "        tly = item['topleft']['y']\n",
    "        brx = item['bottomright']['x']\n",
    "        bry = item['bottomright']['y']\n",
    "        label = item['label']\n",
    "        conf = item['confidence']\n",
    "        if item['label'] == 'person':\n",
    "            tl_x = tlx\n",
    "            tl_y = tly\n",
    "            br_x = brx\n",
    "            br_y = bry\n",
    "    \n",
    "        if conf > 0.6:\n",
    "\n",
    "            for i in class_names:\n",
    "                if label == i:\n",
    "                    class_num = class_names.index(i)\n",
    "                    break\n",
    "\n",
    "            #枠の作成\n",
    "            cv2.rectangle(imgcv, (tlx, tly), (brx, 666), class_colors[class_num], 2)\n",
    "\n",
    "            #ラベルの作成\n",
    "#             text = label + \" \" + ('%.2f' % conf)\n",
    "#             cv2.rectangle(imgcv, (tlx, tly - 15), (tlx + 100, tly + 5), class_colors[class_num], -1)\n",
    "#             cv2.putText(imgcv, text, (tlx, tly), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
    "\n",
    "# 書き出し\n",
    "    im = Image.open(f)\n",
    "    im_crop = im.crop((tl_x,tl_y, br_x, 666))\n",
    "    im_crop.save(f, quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken by network : 0.708\n",
      "Total time taken : 0.720\n",
      "time taken by network : 0.755\n",
      "Total time taken : 0.768\n",
      "time taken by network : 0.723\n",
      "Total time taken : 0.737\n",
      "time taken by network : 0.739\n",
      "Total time taken : 0.752\n",
      "time taken by network : 0.736\n",
      "Total time taken : 0.747\n",
      "time taken by network : 0.728\n",
      "Total time taken : 0.738\n",
      "time taken by network : 0.724\n",
      "Total time taken : 0.735\n",
      "time taken by network : 0.728\n",
      "Total time taken : 0.739\n",
      "time taken by network : 0.727\n",
      "Total time taken : 0.740\n",
      "time taken by network : 0.738\n",
      "Total time taken : 0.750\n",
      "time taken by network : 0.723\n",
      "Total time taken : 0.736\n",
      "time taken by network : 0.727\n",
      "Total time taken : 0.739\n",
      "time taken by network : 0.730\n",
      "Total time taken : 0.742\n",
      "time taken by network : 0.765\n",
      "Total time taken : 0.778\n",
      "time taken by network : 0.731\n",
      "Total time taken : 0.744\n",
      "time taken by network : 0.726\n",
      "Total time taken : 0.737\n",
      "time taken by network : 0.717\n",
      "Total time taken : 0.729\n",
      "time taken by network : 0.723\n",
      "Total time taken : 0.735\n",
      "time taken by network : 0.720\n",
      "Total time taken : 0.732\n"
     ]
    }
   ],
   "source": [
    "# Specify the paths for the 2 files\n",
    "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Read the network into Memory\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "import time\n",
    "MODE = \"MPI\"\n",
    "\n",
    "if MODE is \"COCO\":\n",
    "    protoFile = \"pose/coco/pose_deploy_linevec.prototxt\"\n",
    "    weightsFile = \"pose/coco/pose_iter_440000.caffemodel\"\n",
    "    nPoints = 18\n",
    "    POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "elif MODE is \"MPI\" :\n",
    "    protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "    weightsFile = \"pose_iter_160000.caffemodel\"\n",
    "    nPoints = 15\n",
    "    POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "\n",
    "files = glob.glob(\"./sample_img/*\")\n",
    "for f in files:\n",
    "    frame = cv2.imread(f)\n",
    "    frameCopy = np.copy(frame)\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    threshold = 0.1\n",
    "\n",
    "    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "    t = time.time()\n",
    "    # input image dimensions for the network\n",
    "    inWidth = 368\n",
    "    #368\n",
    "    inHeight = 368\n",
    "    #368\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
    "                              (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    output = net.forward()\n",
    "    print(\"time taken by network : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "    for i in range(nPoints):\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "\n",
    "        if prob > threshold : \n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append(None)\n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
    "            cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "    cv2.imwrite(f, frameCopy)\n",
    "#     cv2.imwrite('./sample_img/Output-Skeleton.jpg', frame)\n",
    "\n",
    "    print(\"Total time taken : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-takaaki",
   "language": "python",
   "name": "py37-takaaki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
